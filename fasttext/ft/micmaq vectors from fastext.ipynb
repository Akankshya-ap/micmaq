{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FastVector:\n",
    "    \"\"\"\n",
    "    Minimal wrapper for fastvector embeddings.\n",
    "    ```\n",
    "    Usage:\n",
    "        $ model = FastVector(vector_file='/path/to/wiki.en.vec')\n",
    "        $ 'apple' in model\n",
    "        > TRUE\n",
    "        $ model['apple'].shape\n",
    "        > (300,)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vector_file='', transform=None):\n",
    "        \"\"\"Read in word vectors in fasttext format\"\"\"\n",
    "        self.word2id = {}\n",
    "\n",
    "        # Captures word order, for export() and translate methods\n",
    "        self.id2word = []\n",
    "\n",
    "        print('reading word vectors from %s' % vector_file)\n",
    "        with open(vector_file, 'r') as f:\n",
    "\t    print ('1') \n",
    "            (self.n_words, self.n_dim) = \\\n",
    "            (int(x) for x in f.readline().rstrip('\\n').split(' '))\n",
    "            self.embed = np.zeros((self.n_words, self.n_dim))\n",
    "            for i, line in enumerate(f):\n",
    "                elems = line.rstrip('\\n').split(' ')\n",
    "                self.word2id[elems[0]] = i\n",
    "                #print (elems[0])\n",
    "                #ini=np.random.rand(300)\n",
    "                self.embed[i] = elems[1:self.n_dim+1]\n",
    "                self.id2word.append(elems[0])\n",
    "        \n",
    "        # Used in translate_inverted_softmax()\n",
    "        self.softmax_denominators = None\n",
    "        \n",
    "        if transform is not None:\n",
    "            print('Applying transformation to embedding')\n",
    "            self.apply_transform(transform)\n",
    "    \n",
    "    def apply_cop(self, matrix,i):\n",
    "        self.embed[i]=matrix[:]\n",
    "    \n",
    "    def export(self, outpath):\n",
    "        \"\"\"\n",
    "        Transforming a large matrix of WordVectors is expensive. \n",
    "        This method lets you write the transformed matrix back to a file for future use\n",
    "        :param The path to the output file to be written \n",
    "        \"\"\"\n",
    "        fout = open(outpath, \"w\")\n",
    "\n",
    "        # Header takes the guesswork out of loading by recording how many lines, vector dims\n",
    "        fout.write(str(self.n_words) + \" \" + str(self.n_dim) + \"\\n\")\n",
    "        for token in self.id2word:\n",
    "            vector_components = [\"%.6f\" % number for number in self[token]]\n",
    "            vector_as_string = \" \".join(vector_components)\n",
    "\n",
    "            out_line = token + \" \" + vector_as_string + \"\\n\"\n",
    "            fout.write(out_line)\n",
    "\n",
    "        fout.close()\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        return key in self.word2id\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.embed[self.word2id[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from /home/apatra/fastText/fastText_multilingual-master/model.vec\n",
      "1\n",
      "[ 0.23514   -0.062265  -0.44914   -0.46058   -0.32173    0.22479\n",
      "  0.59574   -0.16793   -0.20575    0.20684    0.32242   -0.10982\n",
      "  0.21008   -0.5516    -0.22603    0.34196    0.082802  -0.34114\n",
      " -0.53359   -0.23387   -0.56995   -0.36627    0.57409    0.37144\n",
      " -0.021772   0.28574    0.40112   -0.23364   -0.44666   -0.27884\n",
      " -0.010244   0.47763    0.33714    0.10676   -0.30984   -0.14813\n",
      "  0.19915   -0.15576   -0.14592   -0.64859    0.52664   -0.27724\n",
      " -0.0010243  0.41665   -0.28545   -0.022963   0.62326   -0.12353\n",
      " -0.37234   -0.064643   0.26404    0.25081   -0.39588   -0.033541\n",
      "  0.29877   -0.43526    0.33414   -0.65083   -0.38522   -0.36271\n",
      " -0.24256    0.4016    -0.073898   0.13294    0.052566  -0.15048\n",
      "  0.01158    0.65601   -0.32772    0.11772   -0.45992   -0.099391\n",
      "  0.044374  -0.025823   0.23652    0.23804    0.086746  -0.093185\n",
      " -0.45943   -0.07592    0.23819   -0.20339    0.07404    0.25538\n",
      "  0.69033   -0.42739   -0.30136   -0.37114   -0.25807    0.12252\n",
      " -0.33953    0.32143    0.18932    0.50116   -0.20939    0.038764\n",
      "  0.28839   -0.27788    0.25562   -0.1165     0.28398   -0.50353\n",
      "  0.54297    0.38914   -0.22885   -0.22182   -0.40306    0.49801\n",
      "  0.69994   -0.46162   -0.5702     0.43945   -0.21913   -0.37801\n",
      " -0.26841   -0.23379    0.19561   -0.20355    0.070206   0.1899\n",
      " -0.49045   -0.45921   -0.14037    0.2388    -0.26732    0.37962\n",
      " -0.069387   0.50317    0.022322  -0.050799   0.21417    0.058591\n",
      " -0.056591  -0.13394   -0.10746   -0.5288    -0.36935    0.18575\n",
      " -0.62369    0.20419    0.016719   0.4357     0.028916   0.19165\n",
      "  0.34509   -0.010889   0.017478  -0.17159   -0.083706  -0.18657\n",
      "  0.025134   0.25136   -0.29787   -0.089345  -0.40869    0.016012\n",
      " -0.36574    0.72539    0.2332     0.097634   0.076465   0.64379\n",
      " -0.45203    0.018444   0.42614    0.29721    0.058962   0.044846\n",
      "  0.01807    0.24296    0.0039506 -0.19769   -0.12402   -0.32366\n",
      " -0.36434   -0.29425    0.42046   -0.13845    0.14812   -0.34393\n",
      " -0.095249   0.21514    0.023001   0.053898   0.16468    0.084563\n",
      "  0.071143   0.60569   -0.3086     0.73315   -0.2038     0.21493\n",
      "  0.50654    0.44072    0.62908   -0.27744   -0.012424   0.023966\n",
      " -0.028894  -0.20943   -0.13891    0.13876   -0.021577  -0.36779\n",
      "  0.20802    0.060739   0.39414    0.0086703  0.023462  -0.2801\n",
      " -0.23608   -0.15086   -0.07845    0.050722   0.11723    0.099346\n",
      "  0.31162    0.4856    -0.21219   -0.030123   0.027101  -0.27447\n",
      " -0.53788    0.30836    0.044582  -0.2272    -0.021835  -0.038528\n",
      " -0.044213  -0.033613  -0.31194    0.28822   -0.72532   -0.51556\n",
      " -0.097388  -0.014024  -0.4117    -0.049312   0.42391    0.45348\n",
      "  0.28263   -0.37695    0.211      0.65837    0.051328  -0.24846\n",
      "  0.47941   -0.10407   -0.58897    0.39135   -0.29719   -0.27083\n",
      "  0.0775    -0.023555  -0.1137    -0.48187   -0.233     -0.25281\n",
      "  0.0018454  0.09285    0.0081139 -0.21673    0.4566    -0.094376\n",
      " -0.54671    0.74551    0.070565   0.058538   0.021981  -0.0639\n",
      "  0.12674   -0.24321    0.55649   -0.4765    -0.18605   -0.20572\n",
      "  0.30902   -0.31098   -0.17387    0.093865  -0.35337    0.42893\n",
      "  0.40069   -0.16918    0.28796    0.071799   0.25482    0.16699\n",
      " -0.17247    0.032977   0.31798    0.30253    0.54235   -0.45767\n",
      " -0.45923    0.12558   -0.31588    0.29804   -0.21492   -0.43908  ]\n"
     ]
    }
   ],
   "source": [
    "#en_dictionary = FastVector1(vector_file='/home/apatra/fastText/fastText_multilingual-master/eng.vec')\n",
    "mi_dictionary = FastVector(vector_file='/home/apatra/fastText/fastText_multilingual-master/model.vec')\n",
    "\n",
    "#en_vector = en_dictionary[\"one\"]\n",
    "mi_vector = mi_dictionary[\"newt\"]\n",
    "#print(cosine_similarity(en_vector, mi_vector))\n",
    "print mi_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the vecor to file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mi_dictionary.export('/home/apatra/fastText/fastText_multilingual-master/micmaq2.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
