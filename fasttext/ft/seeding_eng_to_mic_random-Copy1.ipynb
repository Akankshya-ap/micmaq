{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "class FastVector:\n",
    "    \"\"\"\n",
    "    Minimal wrapper for fastvector embeddings.\n",
    "    ```\n",
    "    Usage:\n",
    "        $ model = FastVector(vector_file='/path/to/wiki.en.vec')\n",
    "        $ 'apple' in model\n",
    "        > TRUE\n",
    "        $ model['apple'].shape\n",
    "        > (300,)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vector_file='', transform=None):\n",
    "        \"\"\"Read in word vectors in fasttext format\"\"\"\n",
    "        self.word2id = {}\n",
    "\n",
    "        # Captures word order, for export() and translate methods\n",
    "        self.id2word = []\n",
    "\n",
    "        print('reading word vectors from %s' % vector_file)\n",
    "        with open(vector_file, 'r') as f:\n",
    "\t    print ('1') \n",
    "            (self.n_words, self.n_dim) = \\\n",
    "            (int(x) for x in f.readline().rstrip('\\n').split(' '))\n",
    "            self.embed = np.zeros((self.n_words, self.n_dim))\n",
    "            for i, line in enumerate(f):\n",
    "                elems = line.rstrip('\\n').split(' ')\n",
    "                self.word2id[elems[0]] = i\n",
    "                #print (elems[0])\n",
    "                ini=np.random.rand(300)\n",
    "                self.embed[i] = ini[:] #elems[1:self.n_dim+1]\n",
    "                self.id2word.append(elems[0])\n",
    "        \n",
    "        # Used in translate_inverted_softmax()\n",
    "        self.softmax_denominators = None\n",
    "        \n",
    "        if transform is not None:\n",
    "            print('Applying transformation to embedding')\n",
    "            self.apply_transform(transform)\n",
    "    \n",
    "    def apply_cop(self, matrix,i):\n",
    "        self.embed[i]=matrix[:]\n",
    "    \n",
    "    def export(self, outpath):\n",
    "        \"\"\"\n",
    "        Transforming a large matrix of WordVectors is expensive. \n",
    "        This method lets you write the transformed matrix back to a file for future use\n",
    "        :param The path to the output file to be written \n",
    "        \"\"\"\n",
    "        fout = open(outpath, \"w\")\n",
    "\n",
    "        # Header takes the guesswork out of loading by recording how many lines, vector dims\n",
    "        fout.write(str(self.n_words) + \" \" + str(self.n_dim) + \"\\n\")\n",
    "        for token in self.id2word:\n",
    "            vector_components = [\"%.6f\" % number for number in self[token]]\n",
    "            vector_as_string = \" \".join(vector_components)\n",
    "\n",
    "            out_line = token + \" \" + vector_as_string + \"\\n\"\n",
    "            fout.write(out_line)\n",
    "\n",
    "        fout.close()\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def cosine_similarity(cls, vec_a, vec_b):\n",
    "        \"\"\"Compute cosine similarity between vec_a and vec_b\"\"\"\n",
    "        return np.dot(vec_a, vec_b) / \\\n",
    "            (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.word2id\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.embed[self.word2id[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_matrices(source_dictionary, target_dictionary, bilingual_dictionary):\n",
    "    \"\"\"\n",
    "    Source and target dictionaries are the FastVector objects of\n",
    "    source/target languages. bilingual_dictionary is a list of \n",
    "    translation pair tuples [(source_word, target_word), ...].\n",
    "    \"\"\"\n",
    "    source_matrix = []\n",
    "    target_matrix = []\n",
    "    ti=[]\n",
    "    count=0\n",
    "    for (source, target) in bilingual_dictionary:\n",
    "        #print source,target\n",
    "        if source in source_dictionary and target in target_dictionary:\n",
    "            #print source, target\n",
    "            count=count+1\n",
    "            #print source, target\n",
    "            #print source+1\n",
    "            x=randint(0,len(source_dictionary.word2id))\n",
    "\n",
    "            #print x\n",
    "            source1= source_dictionary.id2word[x]\n",
    "            print source, source1,target\n",
    "            ti.append(target_dictionary.word2id[target])\n",
    "            source_matrix.append(source_dictionary[source1])\n",
    "            target_matrix.append(target_dictionary[target])\n",
    "        \n",
    "    # return training matrices\n",
    "    print count\n",
    "    return np.array(source_matrix), np.array(target_matrix), np.array(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from /home/apatra/fastText/fastText_multilingual-master/eng.vec\n",
      "1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ca4d6c9dc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0men_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/apatra/fastText/fastText_multilingual-master/eng.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmi_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/apatra/fastText/fastText_multilingual-master/model.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0men_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"one\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmi_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"newt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-d010eeb9a343>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vector_file, transform)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "en_dictionary = FastVector(vector_file='/home/apatra/fastText/fastText_multilingual-master/eng.vec')\n",
    "mi_dictionary = FastVector(vector_file='/home/apatra/fastText/fastText_multilingual-master/model.vec')\n",
    "\n",
    "en_vector = en_dictionary[\"one\"]\n",
    "mi_vector = mi_dictionary[\"newt\"]\n",
    "print(FastVector.cosine_similarity(en_vector, mi_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_words = set(mi_dictionary.word2id.keys())\n",
    "en_words = set(en_dictionary.word2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "bilingual_dictionary=[]\n",
    "with codecs.open('/home/apatra/fastText/fastText_multilingual-master/eng-mic','r','utf-8') as f:\n",
    "    for line in f:\n",
    "        eng, mic=line.split(', ')\n",
    "        #print eng\n",
    "        eng=eng.strip('\\\"')\n",
    "        #print eng\n",
    "        mic=mic.strip('\\\"')\n",
    "        mic=mic.replace('\\n','')\n",
    "        mic=mic.replace('\"','')\n",
    "        #print eng, mic\n",
    "        bilingual_dictionary.append((eng,mic))\n",
    "#print bilingual_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose do.Then megnatl\n",
      "I I-a nin\n",
      "aboard temovate teppit\n",
      "aboriginal downscaled Lnu\n",
      "abstruse comptons temig\n",
      "adequate AM-7 tepiet\n",
      "adequate Aloe-Vera tepiaq\n",
      "again N1C app\n",
      "alive max. mimajit\n",
      "allow treach ignmuatl\n",
      "almost .vsd suel\n",
      "also Tarbet elg\n",
      "also Gta5 jel\n",
      "always OurPets apjiw\n",
      "and Świata jel\n",
      "and servatory aq\n",
      "another ALAP igtig\n",
      "arrive you-but pegising\n",
      "aside Akin gmetug\n",
      "asleep RRSO nepat\n",
      "at Grabez eteg\n",
      "attached cable-access naspit\n",
      "attached fisico nasteg\n",
      "authority Lyonel alsusuti\n",
      "aware Genesius gejiatl\n",
      "ay Marovo amuj\n",
      "aye anti-alpha amuj\n",
      "battle 10-17-2010 matntimg\n",
      "battle 15-piece matnaggewaqan\n",
      "bear postsynaptically muin\n",
      "beaver Sq.Ft. kopit\n",
      "because 1930s-style muta\n",
      "before 12.5.2017 tmg\n",
      "before dandy gesgmnaq\n",
      "beside Bird-B-Gone gmetug\n",
      "beside 28.55 anapiw\n",
      "blacksmith seana klaptan\n",
      "blaze Kaupanger gnugwaqan\n",
      "bleed Ceej maltewiaq\n",
      "bless Tiazac elapatoq\n",
      "boss IslandDay alsusit\n",
      "boss 1.715 assusit\n",
      "both self-rightous gitg\n",
      "build Settsu eltoq\n",
      "but Mn gatu\n",
      "Canada Jaymie Ganata\n",
      "canoe years--or kwitn\n",
      "caribou visité qalipu\n",
      "chase Firebreathing getanatl\n",
      "city interfaceA gjigan\n",
      "cliff me.Work mtasoq\n",
      "cloud kmax alug\n",
      "cod mamar peju\n",
      "completely SYNDROME lpa\n",
      "confess vLive agnutg\n",
      "cry hour.A etltemit\n",
      "cry Bethany-Kris atgitemit\n",
      "deep Aug1 temig\n",
      "deer svd lentuk\n",
      "detest note-takers masgelmatl\n",
      "direct post-invasion assusit\n",
      "direct 08-15-2013 alsusit\n",
      "discuss PAUSE agnutmajig\n",
      "discussion puyol agnutmaqan\n",
      "disobey goingAnd elistuatl\n",
      "drink Kelapa esamqwat\n",
      "eagle 2008a kitpu\n",
      "earn BlueLink eltoq\n",
      "eel internacionais katew\n",
      "eight Ednaldo ukmuljin\n",
      "ended Naptha gaqiaq\n",
      "endure i.- saputaqatg\n",
      "enjoys Axmacher gesatg\n",
      "enmeshed totoro nasteg\n",
      "enough WNAC tepiet\n",
      "enough CDCA tepiaq\n",
      "eventually Jinyoung glapis\n",
      "exactly pyrex assma\n",
      "exit J.M. tewiet\n",
      "extinct Orama getmenejig\n",
      "far 2.1.9 gneg\n",
      "fight heney matnaggewaqan\n",
      "finally Recidivism glapis\n",
      "finished 9Report gaqiaq\n",
      "first Aug.26 amgwes\n",
      "first drivingly tmg\n",
      "floor rideWe msaqtaqt\n",
      "food MeTa mijipjewei\n",
      "forever submicrometer iapjiw\n",
      "full-grown Bacteriology gisigweg\n",
      "full-grown Altenburger gisigwet\n",
      "gather Iry-Hor megnatl\n",
      "goes 42.68 eliaq\n",
      "goes 199.3 eliet\n",
      "ground Quirante maqamigew\n",
      "handy ≻ tepaw\n",
      "happens texts.This teliaq\n",
      "have 02-23-2017 geggung\n",
      "have 6,065 geggunatl\n",
      "he 2,000m2 telimatl\n",
      "he Geulah negm\n",
      "hear DayLast nutm\n",
      "her PeacePlayers telimatl\n",
      "her A-bomb negm\n",
      "here Gusau tet\n",
      "him intemperate negm\n",
      "hit Guileless taqamatl\n",
      "hundred bOnline gasgiptnnaqan\n",
      "hundred Pfx kaskimtlnaqn\n",
      "hunt Gillihan getanatl\n",
      "immediately 32561 smtug\n",
      "inch Skyknight mtijin\n",
      "instead Ukraine- awna\n",
      "jab Unreliability taqamatl\n",
      "job Convocations lugowaqan\n",
      "jobs Nuttle lugowaqan\n",
      "laborer NetSafe lugowinu\n",
      "land 16795 maqamigew\n",
      "law parri tplutaqan\n",
      "ledge candesartan mtasoq\n",
      "leftover plumbline esgwiet\n",
      "leftover 289.9 esgwiaq\n",
      "life M2N-E mimajuaqan\n",
      "like DRAC gesalatl\n",
      "like RZs gesatg\n",
      "living community.Over mimajuaqan\n",
      "loath krummholz masgelmatl\n",
      "located upper-half eteg\n",
      "located freque epit\n",
      "machine jodorowsky mulin\n",
      "make Childes eltoq\n",
      "man FileServer jinem\n",
      "marker wireless-charging gnugwaqan\n",
      "mature that.Hope gisigweg\n",
      "mature v-card gisigwet\n",
      "member Schlichte naspit\n",
      "message secundus agnutmaqan\n",
      "mill semua mulin\n",
      "missionary mér aniapsuinu\n",
      "money Puech-Haut suliewei\n",
      "month Yozora tepgunset\n",
      "Montreal Maytree Mulian\n",
      "moon sheet.3. tepgunset\n",
      "mud string sisgu\n",
      "must plÃ amujpa\n",
      "named kennywood teluisig\n",
      "named Kotha teluisit\n",
      "native chorismate Lnu\n",
      "near function.To gigjiw\n",
      "near BLASTS tepaw\n",
      "necessary Traver amujpa\n",
      "need Bunyips menuegetoq\n",
      "negotiate have.4. agnutmajig\n",
      "new comprisingan pilei\n",
      "news GRSP agnutmaqan\n",
      "news 39With glusuaqan\n",
      "night governor tekik\n",
      "night Etón tepgig\n",
      "nighttime albanach tekik\n",
      "night-time black-eyes tekik\n",
      "nine включая pesqunatek\n",
      "offshore danner apaqt\n",
      "one sub-lessee newt\n",
      "operates Inotek elugwet\n",
      "other puliyodharai igtig\n",
      "oversee Shitload alsusit\n",
      "oversee electrocoated assusit\n",
      "pack redelivering ilajit\n",
      "path m17 awtij\n",
      "penitent Ambev aniapsuinu\n",
      "perhaps Banda etug\n",
      "permit eatin ignmuatl\n",
      "person Catering- mimajuinu\n",
      "pipe Shalia tmaqan\n",
      "placed Nundy eteg\n",
      "placed CKs epit\n",
      "plan Markussen ilsuteget\n",
      "possess PTEN geggunatl\n",
      "possess Pro.Fit geggung\n",
      "prepare Kanemoto ilajit\n",
      "present SHTML eig\n",
      "profound accumulation. temig\n",
      "promise wimbeldon teplumatl\n",
      "punch envy-free taqamatl\n",
      "pyrexia ViewNX epsimgewei\n",
      "reach suana tepnatl\n",
      "reindeer Bagratuni qalipu\n",
      "remainder InstallESD.dmg esgwiet\n",
      "remainder Selimovic esgwiaq\n",
      "repeat Valler app\n",
      "report 2017Five agnutmaqan\n",
      "request Malma etawet\n",
      "require dekha menuegetoq\n",
      "rich newly-installed milesit\n",
      "river 4-for-10 sipu\n",
      "road Zoonosis awti\n",
      "roast Biotech etoqtasit\n",
      "salmon Dansette plamu\n",
      "says v2.6 teluet\n",
      "sea simatic apaqt\n",
      "seated Bhagavān epit\n",
      "see TICKETS nemitoq\n",
      "see PLos nemiatl\n",
      "see farrington nemitu\n",
      "seek Monotube getanatl\n",
      "seldom over-billing awisiw\n",
      "select front-on megnatl\n",
      "self-determination 5370 alsusuti\n",
      "send off-and-on elgimatl\n",
      "she wannna negm\n",
      "should eaten.I etug\n",
      "sick over-describe gesnugwat\n",
      "silver REPAIRS suliewei\n",
      "sing verwaltet etlintoq\n",
      "sitting Nice-Ville epit\n",
      "situated nsf eteg\n",
      "six post-1993 asukom\n",
      "six Watne asugom\n",
      "skunk xxd apikjilu\n",
      "slate MUPS mtasoq\n",
      "slave SIMO gisteju\n",
      "snake togged mteskm\n",
      "so Piszczek toqo\n",
      "some Брянск alt\n",
      "sometimes Habillage jijuaqa\n",
      "soon L.9 apugjig\n",
      "speak asctime gelusit\n",
      "spiteful SSN getanatl\n",
      "sprout 8,161 saqaliaq\n",
      "stand Wauthier gaqamit\n",
      "story rompers agnutmaqan\n",
      "struggle Jewsbury matnaggewaqan\n",
      "suddenly 50.07 jiniw\n",
      "sufficient Corrimal tepiaq\n",
      "sufficient Peluca tepiet\n",
      "supervise mini-screwdriver alsusit\n",
      "supervise Graelyn assusit\n",
      "talk changingthe etlewistoq\n",
      "talk Jaguares gelusit\n",
      "task Phototrophic lugowaqan\n",
      "tell Half-Mast telimatl\n",
      "ten PWC mtln\n",
      "that screen-filling ala\n",
      "that EZU negla\n",
      "theirs 5.Before negmowowei\n",
      "them monochromic negmow\n",
      "there exeptions ala\n",
      "there destained eig\n",
      "they co-financiers negmow\n",
      "those Terrytoon negla\n",
      "thousand SmartShake pituimtlnaqn\n",
      "thumb Impasse mtijin\n",
      "tired 22-04-2016 gispnet\n",
      "today argile gisgug\n",
      "too Effectene elg\n",
      "totally angioscopy lpa\n",
      "town rosy-colored gutang\n",
      "track dialectric getanatl\n",
      "trail MeMy awti\n",
      "true Xinhuan teliaq\n",
      "two R1150R tapu\n",
      "us octavos ginu\n",
      "view easy-to-execute angamatl\n",
      "war House matntimg\n",
      "we 99-4 ginu\n",
      "weep kalinka atgitemit\n",
      "what IIHow goqwei\n",
      "where Nayee tami\n",
      "wolf wordpressdotcom paqtesm\n",
      "woman measily e'pit\n",
      "word znajdują glusuaqan\n",
      "work witcher elugwet\n",
      "work Leddin lugowaqan\n",
      "worker Parallel.For lugowinu\n",
      "yeah PTBNL amuj\n",
      "yep  amuj\n",
      "yes Photometrics amuj\n",
      "you gà gilew\n",
      "fever cesspit epsimgewei\n",
      "hate Testino masgelmatl\n",
      "love Pauldrons gesatg\n",
      "love pprs gesalatl\n",
      "sleep kfreebsd nepat\n",
      "water law.Do samqwan\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "# form the training matrices\n",
    "#from copy import deepcopy\n",
    "source_matrix, target_matrix ,ti= make_training_matrices(\n",
    "    en_dictionary, mi_dictionary, bilingual_dictionary)\n",
    "#print len(source_matrix), len(target_matrix)\n",
    "# learn and apply the transformation\n",
    "#print ti, len(ti)\n",
    "#target_matrix=deepcopy(source_matrix)\n",
    "#print source_matrix #[60][9], target_matrix[60][9]\n",
    "#transform = learn_transformation(source_matrix, target_matrix)\n",
    "#print type(transform)\n",
    "#print transform[299]\n",
    "#en_dictionary.apply_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nind=6\\np=list_duplicates(ti,ti[ind])\\n#for l in p:\\n #   print l\\nj=np.zeros(300)\\nprint source_matrix[ind]\\nprint source_matrix[191]\\nfor l in p:\\n    for x in l:\\n        j+=source_matrix[x]\\n            \\n    target_matrix[ind]=j[:]/len(l)\\nprint target_matrix[ind]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def list_duplicates(seq, x):\n",
    "    tally = defaultdict(list)\n",
    "    for i,item in enumerate(seq):\n",
    "        tally[item].append(i)\n",
    "    return (locs for key,locs in tally.items() \n",
    "            if key==x)\n",
    "\n",
    "'''\n",
    "ind=6\n",
    "p=list_duplicates(ti,ti[ind])\n",
    "#for l in p:\n",
    " #   print l\n",
    "j=np.zeros(300)\n",
    "print source_matrix[ind]\n",
    "print source_matrix[191]\n",
    "for l in p:\n",
    "    for x in l:\n",
    "        j+=source_matrix[x]\n",
    "            \n",
    "    target_matrix[ind]=j[:]/len(l)\n",
    "print target_matrix[ind]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17377\n",
      "[0, 91, 206]\n",
      "1474\n",
      "[1]\n",
      "16835\n",
      "[2]\n",
      "7099\n",
      "[3, 147]\n",
      "16371\n",
      "[4, 57, 181]\n",
      "9254\n",
      "[5, 74, 234]\n",
      "578\n",
      "[6, 75, 233]\n",
      "52\n",
      "[7, 189]\n",
      "13258\n",
      "[8]\n",
      "17285\n",
      "[9, 171]\n",
      "483\n",
      "[10]\n",
      "648\n",
      "[11, 254]\n",
      "19\n",
      "[12, 14]\n",
      "759\n",
      "[13]\n",
      "19\n",
      "[12, 14]\n",
      "1\n",
      "[15]\n",
      "629\n",
      "[16, 164]\n",
      "1137\n",
      "[17]\n",
      "3340\n",
      "[18, 34]\n",
      "3858\n",
      "[19, 282]\n",
      "683\n",
      "[20, 127, 174, 215]\n",
      "1350\n",
      "[21, 135]\n",
      "5357\n",
      "[22, 73]\n",
      "2411\n",
      "[23, 207]\n",
      "5113\n",
      "[24]\n",
      "945\n",
      "[25, 26, 274, 275, 276]\n",
      "945\n",
      "[25, 26, 274, 275, 276]\n",
      "17133\n",
      "[27, 263]\n",
      "16938\n",
      "[28, 81, 231]\n",
      "2232\n",
      "[29]\n",
      "1291\n",
      "[30]\n",
      "38\n",
      "[31]\n",
      "1185\n",
      "[32, 85]\n",
      "316\n",
      "[33]\n",
      "3340\n",
      "[18, 34]\n",
      "12258\n",
      "[35]\n",
      "11959\n",
      "[36]\n",
      "14274\n",
      "[37, 132]\n",
      "18793\n",
      "[38]\n",
      "3964\n",
      "[39]\n",
      "2260\n",
      "[40, 61, 165, 235]\n",
      "3637\n",
      "[41, 60, 166, 236]\n",
      "2036\n",
      "[42]\n",
      "1365\n",
      "[43, 67, 130]\n",
      "43\n",
      "[44]\n",
      "16956\n",
      "[45]\n",
      "20368\n",
      "[46]\n",
      "6636\n",
      "[47, 186]\n",
      "14312\n",
      "[48, 109, 204, 227, 257]\n",
      "17140\n",
      "[49]\n",
      "7862\n",
      "[50, 119, 219]\n",
      "20729\n",
      "[51]\n",
      "20551\n",
      "[52]\n",
      "1198\n",
      "[53, 255]\n",
      "17138\n",
      "[54]\n",
      "14220\n",
      "[55]\n",
      "13218\n",
      "[56, 265]\n",
      "16371\n",
      "[4, 57, 181]\n",
      "5137\n",
      "[58]\n",
      "14680\n",
      "[59, 126, 279]\n",
      "3637\n",
      "[41, 60, 166, 236]\n",
      "2260\n",
      "[40, 61, 165, 235]\n",
      "16504\n",
      "[62, 152]\n",
      "889\n",
      "[63, 136, 154, 190, 230]\n",
      "17280\n",
      "[64]\n",
      "1776\n",
      "[65]\n",
      "7793\n",
      "[66]\n",
      "1365\n",
      "[43, 67, 130]\n",
      "1124\n",
      "[68]\n",
      "525\n",
      "[69]\n",
      "13743\n",
      "[70, 83]\n",
      "17109\n",
      "[71]\n",
      "15027\n",
      "[72, 124, 280]\n",
      "5357\n",
      "[22, 73]\n",
      "9254\n",
      "[5, 74, 234]\n",
      "578\n",
      "[6, 75, 233]\n",
      "190\n",
      "[76, 82]\n",
      "13784\n",
      "[77]\n",
      "1095\n",
      "[78]\n",
      "16939\n",
      "[79]\n",
      "14987\n",
      "[80]\n",
      "16938\n",
      "[28, 81, 231]\n",
      "190\n",
      "[76, 82]\n",
      "13743\n",
      "[70, 83]\n",
      "17148\n",
      "[84]\n",
      "1185\n",
      "[32, 85]\n",
      "2805\n",
      "[86]\n",
      "949\n",
      "[87]\n",
      "220\n",
      "[88]\n",
      "16584\n",
      "[89, 133]\n",
      "16588\n",
      "[90, 134]\n",
      "17377\n",
      "[0, 91, 206]\n",
      "442\n",
      "[92]\n",
      "177\n",
      "[93]\n",
      "4258\n",
      "[94, 117]\n",
      "4308\n",
      "[95, 149]\n",
      "173\n",
      "[96, 259]\n",
      "1774\n",
      "[97, 178]\n",
      "14980\n",
      "[98, 177]\n",
      "364\n",
      "[99, 102, 240]\n",
      "48\n",
      "[100, 103, 105, 209]\n",
      "9247\n",
      "[101]\n",
      "364\n",
      "[99, 102, 240]\n",
      "48\n",
      "[100, 103, 105, 209]\n",
      "175\n",
      "[104]\n",
      "48\n",
      "[100, 103, 105, 209]\n",
      "15013\n",
      "[106, 113, 183]\n",
      "2303\n",
      "[107]\n",
      "1148\n",
      "[108]\n",
      "14312\n",
      "[48, 109, 204, 227, 257]\n",
      "661\n",
      "[110]\n",
      "4502\n",
      "[111, 251]\n",
      "309\n",
      "[112]\n",
      "15013\n",
      "[106, 113, 183]\n",
      "1926\n",
      "[114, 115, 239, 272]\n",
      "1926\n",
      "[114, 115, 239, 272]\n",
      "14797\n",
      "[116, 273]\n",
      "4258\n",
      "[94, 117]\n",
      "13793\n",
      "[118]\n",
      "7862\n",
      "[50, 119, 219]\n",
      "13589\n",
      "[120, 187]\n",
      "5383\n",
      "[121, 188]\n",
      "186\n",
      "[122, 125]\n",
      "13297\n",
      "[123, 281]\n",
      "15027\n",
      "[72, 124, 280]\n",
      "186\n",
      "[122, 125]\n",
      "14680\n",
      "[59, 126, 279]\n",
      "683\n",
      "[20, 127, 174, 215]\n",
      "1202\n",
      "[128, 175, 200, 214]\n",
      "406\n",
      "[129, 137]\n",
      "1365\n",
      "[43, 67, 130]\n",
      "981\n",
      "[131]\n",
      "14274\n",
      "[37, 132]\n",
      "16584\n",
      "[89, 133]\n",
      "16588\n",
      "[90, 134]\n",
      "1350\n",
      "[21, 135]\n",
      "889\n",
      "[63, 136, 154, 190, 230]\n",
      "406\n",
      "[129, 137]\n",
      "6878\n",
      "[138, 169]\n",
      "1661\n",
      "[139, 212]\n",
      "16315\n",
      "[140, 142]\n",
      "11355\n",
      "[141]\n",
      "16315\n",
      "[140, 142]\n",
      "1498\n",
      "[143]\n",
      "62\n",
      "[144, 150]\n",
      "370\n",
      "[145]\n",
      "251\n",
      "[146]\n",
      "7099\n",
      "[3, 147]\n",
      "497\n",
      "[148]\n",
      "4308\n",
      "[95, 149]\n",
      "62\n",
      "[144, 150]\n",
      "17165\n",
      "[151, 192]\n",
      "16504\n",
      "[62, 152]\n",
      "3059\n",
      "[153]\n",
      "889\n",
      "[63, 136, 154, 190, 230]\n",
      "798\n",
      "[155, 270]\n",
      "9933\n",
      "[156, 158, 159]\n",
      "13158\n",
      "[157]\n",
      "9933\n",
      "[156, 158, 159]\n",
      "9933\n",
      "[156, 158, 159]\n",
      "700\n",
      "[160]\n",
      "4509\n",
      "[161, 199]\n",
      "1268\n",
      "[162]\n",
      "5090\n",
      "[163, 271]\n",
      "629\n",
      "[16, 164]\n",
      "2260\n",
      "[40, 61, 165, 235]\n",
      "3637\n",
      "[41, 60, 166, 236]\n",
      "21490\n",
      "[167, 179]\n",
      "7147\n",
      "[168]\n",
      "6878\n",
      "[138, 169]\n",
      "1576\n",
      "[170, 210]\n",
      "17285\n",
      "[9, 171]\n",
      "328\n",
      "[172]\n",
      "12301\n",
      "[173]\n",
      "683\n",
      "[20, 127, 174, 215]\n",
      "1202\n",
      "[128, 175, 200, 214]\n",
      "2694\n",
      "[176]\n",
      "14980\n",
      "[98, 177]\n",
      "1774\n",
      "[97, 178]\n",
      "21490\n",
      "[167, 179]\n",
      "355\n",
      "[180, 247]\n",
      "16371\n",
      "[4, 57, 181]\n",
      "17157\n",
      "[182]\n",
      "15013\n",
      "[106, 113, 183]\n",
      "16567\n",
      "[184, 278]\n",
      "17161\n",
      "[185]\n",
      "6636\n",
      "[47, 186]\n",
      "13589\n",
      "[120, 187]\n",
      "5383\n",
      "[121, 188]\n",
      "52\n",
      "[7, 189]\n",
      "889\n",
      "[63, 136, 154, 190, 230]\n",
      "21046\n",
      "[191]\n",
      "17165\n",
      "[151, 192]\n",
      "1111\n",
      "[193]\n",
      "1578\n",
      "[194]\n",
      "810\n",
      "[195, 258]\n",
      "11172\n",
      "[196]\n",
      "5201\n",
      "[197]\n",
      "109\n",
      "[198]\n",
      "4509\n",
      "[161, 199]\n",
      "1202\n",
      "[128, 175, 200, 214]\n",
      "1040\n",
      "[201]\n",
      "745\n",
      "[202]\n",
      "603\n",
      "[203]\n",
      "14312\n",
      "[48, 109, 204, 227, 257]\n",
      "1602\n",
      "[205]\n",
      "17377\n",
      "[0, 91, 206]\n",
      "2411\n",
      "[23, 207]\n",
      "14965\n",
      "[208]\n",
      "48\n",
      "[100, 103, 105, 209]\n",
      "1576\n",
      "[170, 210]\n",
      "5110\n",
      "[211]\n",
      "1661\n",
      "[139, 212]\n",
      "15270\n",
      "[213]\n",
      "1202\n",
      "[128, 175, 200, 214]\n",
      "683\n",
      "[20, 127, 174, 215]\n",
      "250\n",
      "[216]\n",
      "5009\n",
      "[217]\n",
      "7139\n",
      "[218]\n",
      "7862\n",
      "[50, 119, 219]\n",
      "2287\n",
      "[220]\n",
      "3839\n",
      "[221]\n",
      "83\n",
      "[222]\n",
      "596\n",
      "[223]\n",
      "739\n",
      "[224]\n",
      "16928\n",
      "[225]\n",
      "15063\n",
      "[226, 238]\n",
      "14312\n",
      "[48, 109, 204, 227, 257]\n",
      "13473\n",
      "[228]\n",
      "973\n",
      "[229]\n",
      "889\n",
      "[63, 136, 154, 190, 230]\n",
      "16938\n",
      "[28, 81, 231]\n",
      "1851\n",
      "[232]\n",
      "578\n",
      "[6, 75, 233]\n",
      "9254\n",
      "[5, 74, 234]\n",
      "2260\n",
      "[40, 61, 165, 235]\n",
      "3637\n",
      "[41, 60, 166, 236]\n",
      "13551\n",
      "[237]\n",
      "15063\n",
      "[226, 238]\n",
      "1926\n",
      "[114, 115, 239, 272]\n",
      "364\n",
      "[99, 102, 240]\n",
      "363\n",
      "[241]\n",
      "527\n",
      "[242, 246]\n",
      "17421\n",
      "[243, 249]\n",
      "17166\n",
      "[244]\n",
      "188\n",
      "[245, 248]\n",
      "527\n",
      "[242, 246]\n",
      "355\n",
      "[180, 247]\n",
      "188\n",
      "[245, 248]\n",
      "17421\n",
      "[243, 249]\n",
      "978\n",
      "[250]\n",
      "4502\n",
      "[111, 251]\n",
      "17259\n",
      "[252]\n",
      "3421\n",
      "[253]\n",
      "648\n",
      "[11, 254]\n",
      "1198\n",
      "[53, 255]\n",
      "17246\n",
      "[256]\n",
      "14312\n",
      "[48, 109, 204, 227, 257]\n",
      "810\n",
      "[195, 258]\n",
      "173\n",
      "[96, 259]\n",
      "2609\n",
      "[260]\n",
      "997\n",
      "[261, 264]\n",
      "2459\n",
      "[262]\n",
      "17133\n",
      "[27, 263]\n",
      "997\n",
      "[261, 264]\n",
      "13218\n",
      "[56, 265]\n",
      "32\n",
      "[266]\n",
      "85\n",
      "[267]\n",
      "13968\n",
      "[268]\n",
      "334\n",
      "[269]\n",
      "798\n",
      "[155, 270]\n",
      "5090\n",
      "[163, 271]\n",
      "1926\n",
      "[114, 115, 239, 272]\n",
      "14797\n",
      "[116, 273]\n",
      "945\n",
      "[25, 26, 274, 275, 276]\n",
      "945\n",
      "[25, 26, 274, 275, 276]\n",
      "945\n",
      "[25, 26, 274, 275, 276]\n",
      "74\n",
      "[277]\n",
      "16567\n",
      "[184, 278]\n",
      "14680\n",
      "[59, 126, 279]\n",
      "15027\n",
      "[72, 124, 280]\n",
      "13297\n",
      "[123, 281]\n",
      "3858\n",
      "[19, 282]\n",
      "107\n",
      "[283]\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "count_no=0\n",
    "j=np.zeros(300)\n",
    "for r in range(0,len(ti)):\n",
    "    #print source_matrix[r], target_matrix[r]\n",
    "    #print len(source_matrix[r]),len(target_matrix[r])\n",
    "    print ti[r]\n",
    "    p=list_duplicates(ti,ti[r])\n",
    "    #print p\n",
    "    j=np.zeros(300)\n",
    "    for l in p:\n",
    "        print l\n",
    "        for x in l:\n",
    "            j+=source_matrix[x]\n",
    "            \n",
    "        target_matrix[r]=j[:]/len(l)\n",
    "    count_no+=1\n",
    "    #target_matrix[r]=source_matrix[r][:]\n",
    "    mi_dictionary.apply_cop(target_matrix[r],ti[r])\n",
    "print count_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mi_dictionary.export('/home/apatra/fastText/fastText_multilingual-master/micmaq5.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(bilingual_dictionary)):\n",
    "    print bilingual_dictionary[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "x=randint(0,len(en_dictionary.word2id))\n",
    "\n",
    "print x\n",
    "print en_dictionary.id2word[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(en_dictionary.word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48037991 0.79621893 0.10069728 0.0968313  0.65611778 0.93605489\n",
      " 0.80080808 0.85866492 0.8851745  0.5600404  0.85136042 0.0253707\n",
      " 0.96636468 0.82165748 0.33783592 0.25417361 0.12928246 0.693545\n",
      " 0.07118339 0.89925375 0.09592868 0.63610351 0.85894757 0.92270126\n",
      " 0.3509721  0.77314531 0.21747356 0.79724538 0.72549369 0.75389477\n",
      " 0.05140413 0.53005763 0.01587389 0.49694558 0.25731754 0.84034813\n",
      " 0.54679512 0.32293218 0.60883597 0.73285294 0.50771891 0.58769128\n",
      " 0.76542808 0.09679181 0.10155699 0.04143743 0.74401417 0.19379413\n",
      " 0.51043834 0.04775789 0.6332428  0.26262762 0.88869964 0.08717218\n",
      " 0.15569276 0.7792916  0.0655121  0.55546958 0.41862344 0.96354461\n",
      " 0.7146249  0.51080211 0.03004831 0.05236235 0.19358396 0.73465263\n",
      " 0.76831993 0.63603409 0.87747971 0.05998253 0.3443728  0.14525981\n",
      " 0.18299494 0.30084732 0.95317339 0.07124013 0.42370739 0.74230851\n",
      " 0.39327503 0.30608549 0.52755995 0.68451904 0.92358112 0.12069464\n",
      " 0.57015554 0.54364173 0.3914261  0.9970799  0.86592304 0.41210059\n",
      " 0.92835937 0.75464255 0.86277212 0.37090642 0.77981556 0.05292197\n",
      " 0.33935419 0.72777378 0.64291755 0.32224732 0.75414924 0.50404174\n",
      " 0.86903144 0.46026839 0.50877971 0.46483942 0.94726289 0.3435239\n",
      " 0.84905293 0.90938335 0.28992895 0.76447628 0.88350912 0.71922005\n",
      " 0.39571242 0.50312279 0.86401707 0.45401393 0.98284498 0.96998614\n",
      " 0.81245406 0.90308677 0.75392647 0.35494545 0.84072369 0.54368296\n",
      " 0.60705576 0.64761793 0.38646143 0.38455768 0.93756972 0.72401913\n",
      " 0.47548434 0.73159072 0.41904042 0.26530117 0.87100955 0.64430887\n",
      " 0.44846291 0.42600357 0.31219817 0.74402132 0.94796896 0.52217793\n",
      " 0.02000188 0.84047747 0.74400632 0.41494102 0.01163145 0.73865891\n",
      " 0.91480059 0.42830842 0.90118773 0.6573488  0.49141339 0.79721865\n",
      " 0.63872434 0.29670234 0.54641536 0.3978702  0.7837987  0.43002809\n",
      " 0.89020542 0.43118608 0.11442037 0.32542568 0.89739613 0.5681394\n",
      " 0.88739641 0.86424154 0.31568987 0.28587284 0.89845204 0.14456471\n",
      " 0.16927878 0.10471355 0.32993796 0.36644243 0.02017006 0.34347929\n",
      " 0.70369752 0.53800571 0.72287728 0.80267412 0.75019548 0.52220068\n",
      " 0.574534   0.55813778 0.15577686 0.07842094 0.82998972 0.11817476\n",
      " 0.93147078 0.83773487 0.07183201 0.17903655 0.52479304 0.39444275\n",
      " 0.10688754 0.87085893 0.32690502 0.54259146 0.27984032 0.03434509\n",
      " 0.90046645 0.72026639 0.6732149  0.49386635 0.78797794 0.26442218\n",
      " 0.42762247 0.31733455 0.37560697 0.40283549 0.0439065  0.91540605\n",
      " 0.44723706 0.87785272 0.65097919 0.16246508 0.67089777 0.71161171\n",
      " 0.43191287 0.54296578 0.50071133 0.56086161 0.34091717 0.75602752\n",
      " 0.35562086 0.41250739 0.10450575 0.15741054 0.24308011 0.70379331\n",
      " 0.40168505 0.59790444 0.62160908 0.1161822  0.04773274 0.13893654\n",
      " 0.93936833 0.59863573 0.78022107 0.41152911 0.45577833 0.61964209\n",
      " 0.29327897 0.36919209 0.57335009 0.07414294 0.20240831 0.88079038\n",
      " 0.36418426 0.14292657 0.70726557 0.33261273 0.16809032 0.92314583\n",
      " 0.93808656 0.43045557 0.82719224 0.1115744  0.42575094 0.58285364\n",
      " 0.51667501 0.72405445 0.74904647 0.42327925 0.75268449 0.20820528\n",
      " 0.27161301 0.72680687 0.12591382 0.68240428 0.64413498 0.44215808\n",
      " 0.34688578 0.79057671 0.32213767 0.07558514 0.59308311 0.57346775\n",
      " 0.56979366 0.25727543 0.52825686 0.08084182 0.21775414 0.696964\n",
      " 0.51085965 0.83575284 0.80971125 0.84569476 0.31209499 0.27266189\n",
      " 0.45368841 0.62927266 0.76257909 0.17246467 0.66770829 0.30849238]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.random.rand(300)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
